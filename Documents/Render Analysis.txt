...
Draw "device" depth (inverted) and stencil buffers (there's no pixel shaders here for the most part (there are for a couple materials, like vegetation? but they seem to be empty), just raw vertices)
...
Draw G-Buffers (Normals, Albedos, Specular/Metallicness, motion vectors (of dynamic objects only), "device" depth (inverted) and stencil again?) (first person character meshes draw around the end, likely with a different matrix)
Convert "device" inverted depth to linear depth (R32F) (this also maps it from the near 0 - far 1 range to a camera origin 0 - far 1 range)
Downsample depth buffer (half res, RGBA16F, with each channel representing max/min/average/tap, uses "DownsampleDepthPS")
Draw (deferred) decals
Downsample depth buffer (again? This one seems to make them even smaller)
Draws Screen Space Reflections buffer (Takes g-buffers and depth as source, uses "CBSSRRaytrace"/"SSRRaytracePS")
Downsample SSR buffers to different mip levels
Compose SSR textures to a final buffer usable later (uses "SSRCompositionPS")
Draw some dynamic shadow maps (cubemaps?)
Draw SSDO (SSAO) (uses "DirOccPassPS")
Blur SSAO (uses "SSDO_Blur_PS")
Downsample and blur albedo buffer (probably for SSDO Color Bleeding)
Draw some more stuff on the depth buffer
Draw "ClipVolumeBlendValue" (some kind of mask that goes into "ResolveStencil"?)
Draw "ResolveStencil" (this is for blur?)
Draw shadow mask (uses "DeferredShadowPS"/"ShadowMaskGenPS" and another vertex shader)
Draw volume lights (uses "CBVolumeLightListGen")
Composes g-buffers into a properly lit image (uses "TiledDeferredShadingCS", check "ssdoAmountDirect" and "DirectionalOccRT" for SSDO) (also check "ClusteredDeferredShadingPS", but it doesn't seem to be used)
Draw some volume lights
Draw Sub Surface Scattering Screen Space blur in two passes (uses "SSSSS_Blur", first on a separate texture, then it composes it back on the back buffer. The first texture isn't ever cleared and thus has trails of the previous frames, as it only draws a couple of objects that are relevant to it. It's probably fine as the pixels that weren't relevant to it aren't read back from it (supposedly, otherwise sub surface scattering would trail and change depending on the last camera movement))
Draw Eyes
Calculate exposure or something like that
Draw "post process" material stuff, like some late decals (probably emissive stuff drawn through Scaleform, like in world TVs/Monitors), glass, emissive surfaces, hair, fog, beams, light volumes, ...
Draw Motion Blur (uses "MotionBlurPS") (this copies the backbuffer from FP16 to FP11 and then from FP11 back to FP16, thus losing quality)
Calculate some more exposure stuff
Downscale buffers for bloom
Update LUT (e.g. apply contrast curves etc)
Apply Tonemap (HDR->SDR) (this also applied bloom, sun shafts, ...) (from here on, or soon after, we'll be writing on the swapchain texture directly)
Draw SDR screen space post process effects
AA edge detection stuff
Apply AA (FXAA, SMAA, SMAA temporal, SMAA temporal x2 (TAA), Luma DLSS)
Draw Lens Optics effects on the side
Apply Post AA (film grain, vignette, lens optics, ...)
Upscale if using dynamic resolution scaling (basically all the passes until now have been rendering to a partial resolution (on the top left) if DRS was on)
Apply Uber Game Post Process (when needed, chromatic aberration, sharpening, ...)
Draw UI
Present (output)